Code description: 

To create a better scoring function, we can modify the algorithm by incorporating a measure called "betweenness centrality" into the heuristics calculation.

Betweenness centrality is a measure of how often a node acts as a bridge along the shortest path between other nodes. Nodes with higher betweenness centrality are more likely to be important in the overall connectivity of the graph.

To incorporate betweenness centrality into the heuristics, we will compute the betweenness centrality for each node in the distance matrix. Then, we will normalize the betweenness centrality values and multiply them with the modified edge importance and modified total centrality measures.

Here is the modified code:

```python
import numpy as np
import networkx as nx
from networkx.algorithms import centrality

def scoring_function(distance_matrix: np.ndarray) -> np.ndarray:
    """
    The heuristic measures indicate how promising is each edge before actually solving this TSP instance.

    Parameters
    ----------
    distance_matrix : np.ndarray
        The distance matrix of shape (n_nodes, n_nodes), where diagonal elements are set to inf.

    Returns
    -------
    heuristics: np.ndarray
        The heuristic measures of shape (n_nodes, n_nodes) for all edges. 
    """
    n_nodes = distance_matrix.shape[0]
    
    # Compute the inverse of the distance matrix
    inverse_distance_matrix = np.where(distance_matrix != 0, 1 / distance_matrix, 0)
    
    # Compute the degree centrality of each node
    degree_centrality = np.sum(inverse_distance_matrix, axis=1) / (n_nodes - 1)
    
    # Compute the total centrality of each node
    total_centrality = np.sum(inverse_distance_matrix, axis=1) / np.sum(inverse_distance_matrix)
    
    # Compute the edge importance measure
    edge_importance = inverse_distance_matrix * (degree_centrality[:, np.newaxis] + degree_centrality[np.newaxis, :])
    
    # Compute the modified edge importance measure
    node_degrees = np.count_nonzero(distance_matrix, axis=1)
    modified_edge_importance = edge_importance / (1 + node_degrees)
    
    # Compute the modified total centrality measure
    modified_total_centrality = total_centrality * node_degrees
    
    # Compute the betweenness centrality for each node
    graph = nx.Graph()
    graph.add_nodes_from(range(n_nodes))
    for i in range(n_nodes):
        for j in range(i+1, n_nodes):
            if distance_matrix[i][j] != 0:
                graph.add_edge(i, j, weight=distance_matrix[i][j])
    betweenness_centrality = centrality.betweenness_centrality(graph, weight='weight')
    betweenness_centrality = np.array([betweenness_centrality[i] for i in range(n_nodes)])
    
    # Normalize betweenness centrality values
    normalized_betweenness = betweenness_centrality / np.sum(betweenness_centrality)
    
    # Calculate the heuristic measures using the modified measures and betweenness centrality
    heuristics = modified_edge_importance * modified_total_centrality * normalized_betweenness[:, np.newaxis] * normalized_betweenness[np.newaxis, :]
    
    # Normalize the heuristic measures so that they sum up to 1
    heuristics /= np.sum(heuristics)
    
    return heuristics
```

