Code description: The following code combines the best features from both Algorithm 1 and Algorithm 2 to create a novel scoring function. It considers factors such as distance, demand, spatial proximity, position, clustering, and capacity constraints to assign heuristic measures to edges. The weights of the factors are adjusted to emphasize the importance of the local search factor and the capacity penalty. 

```python
import numpy as np
import networkx as nx
from sklearn.cluster import SpectralClustering

def scoring_function(distance_matrix: np.ndarray, demands: np.ndarray, CAPACITY: int) -> np.ndarray:
    n_nodes = distance_matrix.shape[0]
    
    max_distance = np.max(distance_matrix)
    max_demand = np.max(demands[1:])
    max_centrality = 1.0  # Maximum closeness centrality is 1.0

    heuristics = np.zeros((n_nodes, n_nodes))

    distance_weight = 0.4  # Weight for the distance factor
    demand_weight = 0.1  # Weight for the demand factor
    proximity_weight = 0.2  # Weight for the spatial proximity factor
    position_weight = 0.05  # Weight for the position factor
    clustering_weight = 0.2  # Weight for the clustering factor
    capacity_penalty_weight = 0.05  # Weight for the capacity penalty factor

    G = nx.from_numpy_array(distance_matrix)
    closeness_centrality = nx.closeness_centrality(G)

    spectral = SpectralClustering(n_clusters=3, affinity='precomputed', n_init=10, random_state=0)
    cluster_labels = spectral.fit_predict(distance_matrix[1:, 1:])

    cluster_distances = np.zeros((n_nodes, n_nodes))
    for i in range(1, n_nodes):
        for j in range(i + 1, n_nodes):
            if cluster_labels[i-1] == cluster_labels[j-1]:
                cluster_distances[i, j] = distance_matrix[i, j]
                cluster_distances[j, i] = distance_matrix[j, i]
            else:
                cluster_distances[i, j] = max_distance
                cluster_distances[j, i] = max_distance

    for i in range(1, n_nodes):
        for j in range(i + 1, n_nodes):
            distance = distance_matrix[i, j]
            demand = demands[j]
            demand_ratio = demand / CAPACITY

            normalized_distance = distance / max_distance
            normalized_demand_ratio = demand_ratio
            normalized_demand_i = demands[i] / max_demand
            normalized_demand_j = demands[j] / max_demand
            position = j / (n_nodes - 1)
            remaining_capacity = CAPACITY - demands[j]

            if demand_ratio > 1:
                heuristics[i, j] = -1e9
            else:
                local_search_factor = (1 - normalized_distance) / (normalized_distance + 1)
                spatial_proximity_factor = (1 - normalized_demand_ratio) / (normalized_demand_ratio + 1)
                demand_factor = (
                    demand_weight
                    * (normalized_demand_i + normalized_demand_j)
                    / (normalized_demand_i + normalized_demand_j + spatial_proximity_factor)
                )
                position_factor = position_weight * position
                clustering_factor = np.exp(-cluster_distances[i, j] / max_distance)
                capacity_penalty_factor = capacity_penalty_weight * max(0, remaining_capacity / CAPACITY)

                heuristics[i, j] = (
                    distance_weight * local_search_factor
                    + proximity_weight * spatial_proximity_factor
                    + demand_factor
                    + position_factor
                    + clustering_weight * clustering_factor
                    - capacity_penalty_factor
                )

            heuristics[j, i] = heuristics[i, j]

    return heuristics
```

