Code description: In this revised scoring function, I will incorporate additional measures to improve the accuracy of the heuristic estimates. I will introduce two new measures: "node importance" and "edge importance". The node importance measure captures the importance of each node in the TSP instance, while the edge importance measure captures the importance of each edge. These measures will be computed based on the centrality of nodes and edges in the distance matrix. The final heuristic measures will be obtained by combining the previously calculated measures with the new node and edge importance measures using a weighted average.

```python
import numpy as np
from scipy.sparse import csr_matrix
from scipy.sparse.csgraph import floyd_warshall
from scipy.sparse.csgraph import connected_components

def scoring_function(distance_matrix: np.ndarray) -> np.ndarray:
    """
    The heuristic measures indicate how promising is each edge before actually solving this TSP instance.

    Parameters
    ----------
    distance_matrix : np.ndarray
        The distance matrix of shape (n_nodes, n_nodes), where diagonal elements are set to inf.

    Returns
    -------
    heuristics: np.ndarray
        The heuristic measures of shape (n_nodes, n_nodes) for all edges. 
    """
    # Define the number of nodes
    n_nodes = distance_matrix.shape[0]

    # Compute the inverse of the distance matrix
    inverse_distance_matrix = np.where(distance_matrix != 0, 1 / distance_matrix, 0)

    # Compute the degree of each node
    node_degrees = np.count_nonzero(distance_matrix, axis=1)

    # Compute the hop count between nodes
    hop_count = floyd_warshall(csr_matrix(distance_matrix, dtype=np.float64))

    # Compute the sum of distances to other nodes for each node
    node_scores = np.sum(inverse_distance_matrix, axis=1)

    # Compute the average distance of connected nodes for each node
    connected_nodes_avg_distance = np.sum(inverse_distance_matrix, axis=1) / (n_nodes - 1)

    # Compute the edge centrality measure
    edge_centrality = np.sum(inverse_distance_matrix, axis=1) / np.sum(inverse_distance_matrix)

    # Compute the edge diversity measure
    edge_diversity = np.sum((distance_matrix != 0), axis=1) / (n_nodes - 1)

    # Compute the neighborhood density measure
    neighborhood_density = np.sum((distance_matrix != 0) & (distance_matrix != np.inf), axis=1) / node_degrees

    # Compute the node centrality measure
    node_centrality = np.sum(inverse_distance_matrix, axis=0) / np.sum(inverse_distance_matrix)

    # Compute the node importance measure
    node_importance = node_centrality / np.max(node_centrality)

    # Compute the edge importance measure
    edge_importance = np.sum(inverse_distance_matrix, axis=0) / np.sum(inverse_distance_matrix)

    # Normalize the edge diversity measure
    normalized_edge_diversity = edge_diversity / np.max(edge_diversity)

    # Repeat the average distances for each edge
    edge_average_distance = np.repeat(connected_nodes_avg_distance[:, np.newaxis], n_nodes, axis=1)

    # Compute the heuristic measures
    heuristics = (inverse_distance_matrix * (1 / node_degrees[:, np.newaxis]) * hop_count * edge_average_distance) / (node_scores[:, np.newaxis] ** 2)

    # Multiply the node degrees with the heuristic measures
    heuristics *= node_degrees[:, np.newaxis]

    # Multiply the edge centrality with the heuristic measures
    heuristics *= edge_centrality[:, np.newaxis]

    # Add the weighted average of normalized edge diversity to the heuristic measures
    alpha = 0.2
    heuristics += alpha * normalized_edge_diversity[:, np.newaxis]

    # Multiply the neighborhood density with the heuristic measures
    heuristics *= neighborhood_density[:, np.newaxis]

    # Multiply the node importance with the heuristic measures
    heuristics *= node_importance[:, np.newaxis]

    # Multiply the edge importance with the heuristic measures
    heuristics *= edge_importance

    # Normalize the heuristic measures
    heuristics /= np.sum(inverse_distance_matrix)

    return heuristics
```

