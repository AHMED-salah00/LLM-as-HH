[*] Running ...
[*] Dataset loaded: /Users/yhr/Desktop/llm-workspace/llm-as-meta-optimizer/problems/cvrp_aco/dataset/val20_dataset.npy with 5 instances.
[*] Instance 0: 9.855732592126452
[*] Instance 1: 10.360446163801011
Traceback (most recent call last):
  File "/Users/yhr/Desktop/llm-workspace/llm-as-meta-optimizer/problems/cvrp_aco/eval.py", line 33, in <module>
    obj = aco.run(N_ITERATIONS)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yhr/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yhr/Desktop/llm-workspace/llm-as-meta-optimizer/problems/cvrp_aco/aco.py", line 45, in run
    paths = self.gen_path()
            ^^^^^^^^^^^^^^^
  File "/Users/yhr/Desktop/llm-workspace/llm-as-meta-optimizer/problems/cvrp_aco/aco.py", line 89, in gen_path
    actions = self.pick_move(actions, visit_mask, capacity_mask)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yhr/Desktop/llm-workspace/llm-as-meta-optimizer/problems/cvrp_aco/aco.py", line 101, in pick_move
    dist = Categorical(dist)
           ^^^^^^^^^^^^^^^^^
  File "/Users/yhr/anaconda3/lib/python3.11/site-packages/torch/distributions/categorical.py", line 66, in __init__
    super().__init__(batch_shape, validate_args=validate_args)
  File "/Users/yhr/anaconda3/lib/python3.11/site-packages/torch/distributions/distribution.py", line 62, in __init__
    raise ValueError(
ValueError: Expected parameter probs (Tensor of shape (30, 21)) of distribution Categorical(probs: torch.Size([30, 21])) to satisfy the constraint Simplex(), but found invalid values:
tensor([[ 0.0523,  0.0577,  0.0563,  0.0000,  0.0607,  0.0545,  0.0659,  0.0550,
          0.0532,  0.0542,  0.0538,  0.0532,  0.0524,  0.0481,  0.0519,  0.0427,
          0.0392,  0.0436,  0.0460,  0.0416,  0.0176],
        [ 0.0509,  0.0636,  0.0536,  0.0572,  0.0542,  0.0522,  0.0605,  0.0547,
          0.0544,  0.0535,  0.0544,  0.0513,  0.0512,  0.0488,  0.0487,  0.0355,
          0.0421,  0.0366,  0.0000,  0.0393,  0.0372],
        [ 0.0524,  0.0580,  0.0568,  0.0541,  0.0609,  0.0549,  0.0676,  0.0559,
          0.0000,  0.0545,  0.0531,  0.0534,  0.0525,  0.0481,  0.0522,  0.0413,
          0.0380,  0.0421,  0.0454,  0.0424,  0.0163],
        [ 0.0521,  0.0743,  0.0561,  0.0588,  0.0654,  0.0545,  0.0656,  0.0537,
          0.0561,  0.0525,  0.0562,  0.0532,  0.0523,  0.0456,  0.0498,  0.0505,
          0.0383,  0.0000,  0.0411,  0.0234,  0.0005],
        [ 0.0524,  0.0857,  0.0529,  0.0654,  0.0632,  0.0531,  0.0000,  0.0568,
          0.0597,  0.0552,  0.0596,  0.0528,  0.0529,  0.0472,  0.0480,  0.0348,
          0.0495,  0.0356,  0.0431,  0.0159,  0.0159],
        [ 0.0507,  0.0732,  0.0543,  0.0614,  0.0522,  0.0529,  0.0642,  0.0570,
          0.0561,  0.0545,  0.0556,  0.0514,  0.0512,  0.0000,  0.0473,  0.0289,
          0.0399,  0.0297,  0.0455,  0.0310,  0.0432],
        [ 0.0504,  0.0719,  0.0533,  0.0605,  0.0520,  0.0521,  0.0614,  0.0559,
          0.0556,  0.0539,  0.0553,  0.0508,  0.0508,  0.0495,  0.0471,  0.0300,
          0.0416,  0.0309,  0.0464,  0.0308,  0.0000],
        [ 0.0524,  0.0580,  0.0568,  0.0541,  0.0609,  0.0549,  0.0676,  0.0559,
          0.0000,  0.0545,  0.0531,  0.0534,  0.0525,  0.0481,  0.0522,  0.0413,
          0.0380,  0.0421,  0.0454,  0.0424,  0.0163],
        [ 0.0524,  0.0653,  0.0569,  0.0554,  0.0634,  0.0549,  0.0675,  0.0550,
          0.0542,  0.0539,  0.0545,  0.0535,  0.0000,  0.0470,  0.0515,  0.0456,
          0.0377,  0.0463,  0.0433,  0.0337,  0.0079],
        [ 0.0507,  0.0692,  0.0540,  0.0598,  0.0000,  0.0526,  0.0630,  0.0562,
          0.0553,  0.0541,  0.0550,  0.0513,  0.0511,  0.0500,  0.0478,  0.0310,
          0.0405,  0.0319,  0.0471,  0.0350,  0.0445],
        [ 0.0523,  0.0781,  0.0562,  0.0605,  0.0665,  0.0547,  0.0653,  0.0540,
          0.0571,  0.0000,  0.0572,  0.0534,  0.0525,  0.0454,  0.0496,  0.0500,
          0.0387,  0.0501,  0.0404,  0.0199, -0.0020],
        [ 0.0513,  0.0749,  0.0528,  0.0613,  0.0573,  0.0519,  0.0568,  0.0556,
          0.0569,  0.0542,  0.0568,  0.0000,  0.0518,  0.0483,  0.0479,  0.0340,
          0.0466,  0.0350,  0.0468,  0.0269,  0.0329],
        [ 0.0507,  0.0732,  0.0543,  0.0614,  0.0522,  0.0529,  0.0642,  0.0570,
          0.0561,  0.0545,  0.0556,  0.0514,  0.0512,  0.0000,  0.0473,  0.0289,
          0.0399,  0.0297,  0.0455,  0.0310,  0.0432],
        [ 0.0525,  0.0608,  0.0573,  0.0558,  0.0613,  0.0552,  0.0693,  0.0567,
          0.0533,  0.0549,  0.0000,  0.0535,  0.0526,  0.0481,  0.0518,  0.0398,
          0.0369,  0.0404,  0.0444,  0.0411,  0.0143],
        [ 0.0524,  0.0857,  0.0529,  0.0654,  0.0632,  0.0531,  0.0000,  0.0568,
          0.0597,  0.0552,  0.0596,  0.0528,  0.0529,  0.0472,  0.0480,  0.0348,
          0.0495,  0.0356,  0.0431,  0.0159,  0.0159],
        [ 0.0522,  0.0772,  0.0566,  0.0599,  0.0667,  0.0548,  0.0668,  0.0544,
          0.0566,  0.0526,  0.0567,  0.0534,  0.0524,  0.0452,  0.0497,  0.0000,
          0.0374,  0.0506,  0.0399,  0.0205, -0.0036],
        [ 0.0522,  0.0709,  0.0553,  0.0580,  0.0631,  0.0538,  0.0621,  0.0000,
          0.0559,  0.0530,  0.0562,  0.0530,  0.0524,  0.0467,  0.0500,  0.0463,
          0.0413,  0.0476,  0.0439,  0.0280,  0.0103],
        [ 0.0524,  0.0653,  0.0569,  0.0554,  0.0634,  0.0549,  0.0675,  0.0550,
          0.0542,  0.0539,  0.0545,  0.0535,  0.0000,  0.0470,  0.0515,  0.0456,
          0.0377,  0.0463,  0.0433,  0.0337,  0.0079],
        [ 0.0523,  0.0577,  0.0563,  0.0000,  0.0607,  0.0545,  0.0659,  0.0550,
          0.0532,  0.0542,  0.0538,  0.0532,  0.0524,  0.0481,  0.0519,  0.0427,
          0.0392,  0.0436,  0.0460,  0.0416,  0.0176],
        [ 0.0523,  0.0883,  0.0000,  0.0666,  0.0633,  0.0532,  0.0541,  0.0574,
          0.0602,  0.0555,  0.0600,  0.0528,  0.0529,  0.0471,  0.0475,  0.0327,
          0.0508,  0.0334,  0.0424,  0.0135,  0.0160],
        [ 0.0524,  0.0857,  0.0529,  0.0654,  0.0632,  0.0531,  0.0000,  0.0568,
          0.0597,  0.0552,  0.0596,  0.0528,  0.0529,  0.0472,  0.0480,  0.0348,
          0.0495,  0.0356,  0.0431,  0.0159,  0.0159],
        [ 0.0523,  0.0577,  0.0563,  0.0000,  0.0607,  0.0545,  0.0659,  0.0550,
          0.0532,  0.0542,  0.0538,  0.0532,  0.0524,  0.0481,  0.0519,  0.0427,
          0.0392,  0.0436,  0.0460,  0.0416,  0.0176],
        [ 0.0507,  0.0732,  0.0543,  0.0614,  0.0522,  0.0529,  0.0642,  0.0570,
          0.0561,  0.0545,  0.0556,  0.0514,  0.0512,  0.0000,  0.0473,  0.0289,
          0.0399,  0.0297,  0.0455,  0.0310,  0.0432],
        [ 0.0522,  0.0772,  0.0566,  0.0599,  0.0667,  0.0548,  0.0668,  0.0544,
          0.0566,  0.0526,  0.0567,  0.0534,  0.0524,  0.0452,  0.0497,  0.0000,
          0.0374,  0.0506,  0.0399,  0.0205, -0.0036],
        [ 0.0521,  0.0896,  0.0526,  0.0671,  0.0628,  0.0532,  0.0555,  0.0578,
          0.0603,  0.0556,  0.0600,  0.0526,  0.0527,  0.0471,  0.0471,  0.0308,
          0.0000,  0.0315,  0.0420,  0.0123,  0.0174],
        [ 0.0521,  0.0896,  0.0526,  0.0671,  0.0628,  0.0532,  0.0555,  0.0578,
          0.0603,  0.0556,  0.0600,  0.0526,  0.0527,  0.0471,  0.0471,  0.0308,
          0.0000,  0.0315,  0.0420,  0.0123,  0.0174],
        [ 0.0523,  0.0781,  0.0562,  0.0605,  0.0665,  0.0547,  0.0653,  0.0540,
          0.0571,  0.0000,  0.0572,  0.0534,  0.0525,  0.0454,  0.0496,  0.0500,
          0.0387,  0.0501,  0.0404,  0.0199, -0.0020],
        [ 0.0521,  0.0743,  0.0561,  0.0588,  0.0654,  0.0545,  0.0656,  0.0537,
          0.0561,  0.0525,  0.0562,  0.0532,  0.0523,  0.0456,  0.0498,  0.0505,
          0.0383,  0.0000,  0.0411,  0.0234,  0.0005],
        [ 0.0524,  0.0653,  0.0569,  0.0554,  0.0634,  0.0549,  0.0675,  0.0550,
          0.0542,  0.0539,  0.0545,  0.0535,  0.0000,  0.0470,  0.0515,  0.0456,
          0.0377,  0.0463,  0.0433,  0.0337,  0.0079],
        [ 0.0523,  0.0883,  0.0000,  0.0666,  0.0633,  0.0532,  0.0541,  0.0574,
          0.0602,  0.0555,  0.0600,  0.0528,  0.0529,  0.0471,  0.0475,  0.0327,
          0.0508,  0.0334,  0.0424,  0.0135,  0.0160]], dtype=torch.float64)
