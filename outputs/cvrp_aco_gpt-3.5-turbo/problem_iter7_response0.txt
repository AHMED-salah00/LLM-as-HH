Code description: 
My new scoring function will combine the best features from both Algorithm 1 and Algorithm 2 to create a more effective scoring function. It will consider the local search factor, spatial proximity factor, demand, distance, position, clustering, and capacity constraints to assign heuristic measures to edges. The weight distribution will be adjusted to enhance the importance of the local search factor and capacity penalty.

```python
import numpy as np
import networkx as nx
from sklearn.cluster import KMeans

def scoring_function(distance_matrix: np.ndarray, demands: np.ndarray, CAPACITY: int) -> np.ndarray:
    n_nodes = distance_matrix.shape[0]

    max_distance = np.max(distance_matrix)
    max_demand = np.max(demands[1:])

    heuristics = np.zeros((n_nodes, n_nodes))

    distance_weight = 0.5  # Weight for the local search factor
    proximity_weight = 0.3  # Weight for the spatial proximity factor
    demand_weight = 0.1  # Weight for the demand factor
    position_weight = 0.05  # Weight for the position factor
    clustering_weight = 0.05  # Weight for the clustering factor
    capacity_penalty_weight = 0.3  # Weight for the capacity penalty factor

    G = nx.from_numpy_array(distance_matrix)
    degree_centrality = nx.degree_centrality(G)

    kmeans = KMeans(n_clusters=3)
    cluster_labels = kmeans.fit_predict(distance_matrix[1:, 1:])

    cluster_distances = np.zeros((n_nodes, n_nodes))
    for i in range(1, n_nodes):
        for j in range(i + 1, n_nodes):
            if cluster_labels[i-1] == cluster_labels[j-1]:
                cluster_distances[i, j] = distance_matrix[i, j]
                cluster_distances[j, i] = distance_matrix[j, i]
            else:
                cluster_distances[i, j] = max_distance
                cluster_distances[j, i] = max_distance

    for i in range(1, n_nodes):
        for j in range(i + 1, n_nodes):
            distance = distance_matrix[i, j]
            demand_ratio = demands[j] / CAPACITY

            normalized_distance = distance / max_distance
            normalized_demand_ratio = demand_ratio
            normalized_demand_i = demands[i] / max_demand
            normalized_demand_j = demands[j] / max_demand
            position = j / (n_nodes - 1)
            remaining_capacity = CAPACITY - demands[j]

            if demand_ratio > 1:
                heuristics[i, j] = -1e9
            else:
                local_search_factor = (1 - normalized_distance) / (
                    degree_centrality[i] + degree_centrality[j]
                )
                proximity_factor = (1 - normalized_demand_ratio) / (
                    degree_centrality[i] + degree_centrality[j]
                )
                demand_factor = (
                    demand_weight
                    * (
                        normalized_demand_i
                        + normalized_demand_j
                    )
                    / (
                        normalized_demand_i
                        + normalized_demand_j
                        + proximity_factor
                    )
                )
                position_factor = position_weight * position
                clustering_factor = np.exp(
                    -cluster_distances[i, j] / max_distance
                )
                capacity_penalty_factor = (
                    capacity_penalty_weight
                    * max(0, remaining_capacity / CAPACITY)
                )

                heuristics[i, j] = (
                    distance_weight * local_search_factor
                    + proximity_weight * proximity_factor
                    + demand_factor
                    + position_factor
                    + clustering_weight * clustering_factor
                    - capacity_penalty_factor
                )

            heuristics[j, i] = heuristics[i, j]

    return heuristics
```

