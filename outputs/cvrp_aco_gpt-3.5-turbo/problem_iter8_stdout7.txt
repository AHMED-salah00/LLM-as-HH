[*] Running ...
[*] Dataset loaded: /Users/yhr/Desktop/llm-workspace/llm-as-meta-optimizer/problems/cvrp_aco/dataset/val20_dataset.npy with 5 instances.
/Users/yhr/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning
  warnings.warn(
Traceback (most recent call last):
  File "/Users/yhr/Desktop/llm-workspace/llm-as-meta-optimizer/problems/cvrp_aco/eval.py", line 33, in <module>
    obj = aco.run(N_ITERATIONS)
          ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yhr/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yhr/Desktop/llm-workspace/llm-as-meta-optimizer/problems/cvrp_aco/aco.py", line 45, in run
    paths = self.gen_path()
            ^^^^^^^^^^^^^^^
  File "/Users/yhr/Desktop/llm-workspace/llm-as-meta-optimizer/problems/cvrp_aco/aco.py", line 89, in gen_path
    actions = self.pick_move(actions, visit_mask, capacity_mask)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yhr/Desktop/llm-workspace/llm-as-meta-optimizer/problems/cvrp_aco/aco.py", line 101, in pick_move
    dist = Categorical(dist)
           ^^^^^^^^^^^^^^^^^
  File "/Users/yhr/anaconda3/lib/python3.11/site-packages/torch/distributions/categorical.py", line 66, in __init__
    super().__init__(batch_shape, validate_args=validate_args)
  File "/Users/yhr/anaconda3/lib/python3.11/site-packages/torch/distributions/distribution.py", line 62, in __init__
    raise ValueError(
ValueError: Expected parameter probs (Tensor of shape (30, 21)) of distribution Categorical(probs: torch.Size([30, 21])) to satisfy the constraint Simplex(), but found invalid values:
tensor([[-0., -0., nan, -0., nan, nan, nan, nan, nan, nan, nan, nan, -0., nan, nan, nan, nan, nan, nan, nan, nan],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., -0., nan, -0., nan, nan, nan, nan, nan, nan, nan, nan, -0., nan, nan, nan, nan, nan, nan, nan, nan],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., -0., nan, -0., nan, nan, nan, nan, nan, nan, nan, nan, -0., nan, nan, nan, nan, nan, nan, nan, nan],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., -0., nan, -0., nan, nan, nan, nan, nan, nan, nan, nan, -0., nan, nan, nan, nan, nan, nan, nan, nan],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., -0., nan, -0., nan, nan, nan, nan, nan, nan, nan, nan, -0., nan, nan, nan, nan, nan, nan, nan, nan],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, -0., -0., nan, -0., nan],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., -0., nan, -0., nan, nan, nan, nan, nan, nan, nan, nan, -0., nan, nan, nan, nan, nan, nan, nan, nan],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.],
        [-0., nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, -0., -0., nan, -0., nan],
        [-0., -0., nan, -0., nan, nan, nan, nan, nan, nan, nan, nan, -0., nan, nan, nan, nan, nan, nan, nan, nan],
        [-0., nan, -0., nan, -0., -0., -0., -0., -0., -0., -0., -0., nan, -0., -0., -0., nan, nan, -0., nan, -0.]],
       dtype=torch.float64)
