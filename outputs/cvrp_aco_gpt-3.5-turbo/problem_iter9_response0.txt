Code description: In this improved scoring function, I will combine the factors from Algorithm 1 and Algorithm 2 to create a more effective scoring function. I will consider the distance, demand, position, degree centrality, clustering, local search, and capacity penalty factors. I will adjust the weights of the factors to optimize their contributions to the final heuristic measures. Additionally, I will initialize the heuristics matrix outside the loop for efficiency.

```python
import numpy as np
from sklearn.cluster import KMeans
import networkx as nx

def scoring_function(distance_matrix: np.ndarray, demands: np.ndarray, CAPACITY: int) -> np.ndarray:
    n_nodes = distance_matrix.shape[0]
    
    max_distance = np.max(distance_matrix)
    max_demand = np.max(demands[1:])
    
    heuristics = np.zeros((n_nodes, n_nodes))
    
    distance_weight = 0.35  
    demand_weight = 0.15  
    position_weight = 0.1  
    degree_centrality_weight = 0.3  
    clustering_weight = 0.1  
    local_search_weight = 0.3  
    capacity_penalty_weight = 0.3  
    
    
    # Calculate the degree centrality of nodes
    adjacency_matrix = np.where(distance_matrix > 0, 1, 0)
    G = nx.from_numpy_array(adjacency_matrix)
    degree_centrality_values = list(nx.degree_centrality(G).values())
    degree_centrality_sum = sum(degree_centrality_values)
    degree_centrality_values = [degree / degree_centrality_sum for degree in degree_centrality_values]
    
    kmeans = KMeans(n_clusters=3)
    cluster_labels = kmeans.fit_predict(distance_matrix[1:, 1:])
    
    cluster_distances = np.zeros((n_nodes, n_nodes))
    for i in range(1, n_nodes):
        for j in range(i + 1, n_nodes):
            if cluster_labels[i-1] == cluster_labels[j-1]:
                cluster_distances[i, j] = distance_matrix[i, j]
                cluster_distances[j, i] = distance_matrix[j, i]
            else:
                cluster_distances[i, j] = max_distance
                cluster_distances[j, i] = max_distance
    
    for i in range(1, n_nodes):
        for j in range(i + 1, n_nodes):
            distance = distance_matrix[i, j]
            demand_ratio = demands[j] / CAPACITY
            position = j / (n_nodes - 1)
            degree_centrality = degree_centrality_values[j - 1]
            cluster_distance = cluster_distances[i, j]
            
            normalized_distance = distance / max_distance
            normalized_demand_ratio = demand_ratio
            normalized_position = position
            normalized_degree_centrality = degree_centrality / np.max(degree_centrality_values)
            normalized_cluster_distance = cluster_distance / max_distance
            
            local_search_factor = (1 - normalized_distance) / degree_centrality
            clustering_factor = 1 - normalized_cluster_distance
            capacity_penalty_factor = capacity_penalty_weight * max(0, demands[i] + demands[j] - CAPACITY) / CAPACITY
            
            heuristics[i, j] = (
                distance_weight * normalized_distance +
                demand_weight * normalized_demand_ratio +
                position_weight * normalized_position +
                degree_centrality_weight * normalized_degree_centrality +
                clustering_weight * clustering_factor +
                local_search_weight * local_search_factor - 
                capacity_penalty_weight * capacity_penalty_factor
            )
            
            # Symmetrically set heuristics for the lower triangle of the matrix
            heuristics[j, i] = heuristics[i, j]
    
    return heuristics
```

